name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  build-test:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/pyproject.toml') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Install project (dev extras)
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]

      # NEW: matplotlib for snapshot script (keeps pyproject unchanged)
      - name: Install extra plotting dep
        run: |
          pip install matplotlib

      - name: Pre-commit (lint/format/sqlfluff)
        run: |
          pre-commit run --all-files || (echo "Pre-commit found issues"; exit 1)

      - name: Prepare folders
        run: |
          mkdir -p warehouse artifacts/logs exports site data/synth data/real

      - name: Create .env
        run: |
          cp .env.example .env
          echo "MODE=real" >> .env
          echo "DUCKDB_PATH=warehouse/nomad.duckdb" >> .env
          echo "DBT_PROFILES_DIR=./dbt" >> .env

      # ---- Real-world ingest requires Olist CSVs. For CI we fetch a tiny sample to prove the pipeline.
      - name: Fetch small Olist sample (subset)
        run: |
          python - <<'PY'
import pandas as pd, os
os.makedirs("data/real", exist_ok=True)
def w(name, df):
    df.to_csv(f"data/real/{name}", index=False)
# Minimal headers to satisfy ingest & models; 200 rows each
w("olist_orders_dataset.csv", pd.DataFrame({
    "order_id": [f"o{i:05d}" for i in range(1,201)],
    "customer_id": [f"c{(i%80)+1:04d}" for i in range(1,201)],
    "order_status": ["delivered"]*200,
    "order_purchase_timestamp": pd.date_range("2018-01-01", periods=200, freq="D").astype("datetime64[ns]"),
    "order_approved_at": pd.date_range("2018-01-01", periods=200, freq="D").astype("datetime64[ns]"),
    "order_delivered_carrier_date": pd.date_range("2018-01-03", periods=200, freq="D").astype("datetime64[ns]"),
    "order_delivered_customer_date": pd.date_range("2018-01-05", periods=200, freq="D").astype("datetime64[ns]"),
    "order_estimated_delivery_date": pd.date_range("2018-01-06", periods=200, freq="D").astype("datetime64[ns]"),
}))
w("olist_order_items_dataset.csv", pd.DataFrame({
    "order_id": [f"o{i:05d}" for i in range(1,201) for _ in (0,1)],
    "order_item_id": [1,2]*200,
    "product_id": [f"p{(i%50)+1:04d}" for i in range(1,401)],
    "seller_id": [f"s{(i%30)+1:03d}" for i in range(1,401)],
    "price": [100.0]*400,
    "freight_value": [10.0]*400,
}))
w("olist_customers_dataset.csv", pd.DataFrame({
    "customer_id": [f"c{i:04d}" for i in range(1,201)],
    "customer_unique_id": [f"u{i:04d}" for i in range(1,201)],
    "customer_city": ["city"]*200,
    "customer_state": ["SP"]*200,
    "customer_zip_code_prefix": ["01000"]*200,
}))
w("olist_order_payments_dataset.csv", pd.DataFrame({
    "order_id": [f"o{i:05d}" for i in range(1,201)],
    "payment_sequential": [1]*200,
    "payment_type": ["credit_card"]*200,
    "payment_installments": [1]*200,
    "payment_value": [200.0]*200,
}))
w("olist_order_reviews_dataset.csv", pd.DataFrame({
    "review_id": [f"r{i:05d}" for i in range(1,201)],
    "order_id": [f"o{i:05d}" for i in range(1,201)],
    "review_score": [5]*200,
    "review_creation_date": pd.date_range("2018-01-06", periods=200, freq="D").astype("datetime64[ns]"),
    "review_answer_timestamp": pd.date_range("2018-01-07", periods=200, freq="D").astype("datetime64[ns]"),
}))
w("olist_products_dataset.csv", pd.DataFrame({
    "product_id": [f"p{i:04d}" for i in range(1,51)],
    "product_category_name": ["misc"]*50,
    "product_name_lenght": [10]*50,
    "product_description_lenght": [50]*50,
    "product_photos_qty": [1]*50,
    "product_weight_g": [100]*50,
    "product_length_cm": [10]*50,
    "product_height_cm": [5]*50,
    "product_width_cm": [5]*50,
}))
w("olist_sellers_dataset.csv", pd.DataFrame({
    "seller_id": [f"s{i:03d}" for i in range(1,31)],
    "seller_city": ["city"]*30,
    "seller_state": ["SP"]*30,
    "seller_zip_code_prefix": ["02000"]*30,
}))
w("olist_geolocation_dataset.csv", pd.DataFrame({
    "geolocation_zip_code_prefix": ["01000","02000"],
    "geolocation_city": ["city","city"],
    "geolocation_state": ["SP","SP"],
    "geolocation_lat": [-23.55,-23.50],
    "geolocation_lng": [-46.63,-46.60],
}))
PY

      - name: Ingest sample data (real mode)
        run: |
          python scripts/ingest_olist.py --source real --db warehouse/nomad.duckdb

      - name: Quality checks
        run: |
          python scripts/quality_checks.py --db warehouse/nomad.duckdb --mode real

      - name: dbt deps
        run: |
          dbt deps --project-dir dbt --profiles-dir dbt

      - name: dbt build + tests
        run: |
          dbt build --project-dir dbt --profiles-dir dbt --vars 'mode: real'

      - name: Run unit tests
        run: |
          pytest -q

      # NEW: generate PNGs from KPI tables (non-fatal if no data)
      - name: Generate KPI screenshots
        run: |
          python scripts/snapshot_db_docs.py || true

      # NEW: upload charts + dbt site as build artifacts
      - name: Upload artifacts (charts & site)
        uses: actions/upload-artifact@v4
        with:
          name: analytics-artifacts
          path: |
            artifacts/*.png
            site/
          if-no-files-found: warn
